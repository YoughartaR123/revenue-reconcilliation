# ============================================================================
# AUTOMATED MONTHLY PIPELINE SETUP (Windows Task Scheduler)
# ============================================================================
#
# STEP 1: Open Task Scheduler
#         Win + R ‚Üí taskschd.msc ‚Üí Enter
#
# STEP 2: Create a New Task
#         - Click "Create Basic Task"
#         - Name: RevenueReconciliation
#         - Trigger: Monthly (select day/time)
#         - Action: Start a program
#           * Program/script: python.exe
#           * Arguments: C:\path\to\revenue_reconciliation.py
#           * Start in: C:\path\to\your\project
#
# STEP 3: Save and Test
#         Right-click task ‚Üí Run (to test immediately)
#
# ============================================================================


# ============================================================================
# üîí DATA PRIVACY & TESTING METHODOLOGY
# ============================================================================
#
# IMPORTANT: Revenue reconciliation data is highly sensitive (contract values,
# customer deals, revenue recognition entries). To ensure privacy while
# maintaining realistic testing:
#
# ‚Üí This project uses SYNTHETIC DATA generated by AI
# ‚Üí Replicates real-world complexity and data quality issues:
#     - Timing differences
#     - Missing entries
#     - Currency mismatches
#     - Recognition rule variations
#
# ‚Üí Contains NO actual customer or financial information
# ‚Üí Allows rigorous testing without compromising sensitive corporate data
#
# ============================================================================



######################### Dataset Description ################################

# ============================================================================
# BOOKED REVENUE (Sales/CRM System) - When deals are signed
# ============================================================================
# deal_id                  : Unique deal identifier (e.g., DEAL-10001)
# customer_name            : Company that purchased (e.g., TechSystems Inc.)
# sales_rep                : Sales rep who closed deal (e.g., Rep_1)
# contract_date            : Contract signing date (e.g., 2023-03-15)
# contract_value           : Total contract value (e.g., $120,000.00)
# product_service_type     : Product/service sold (e.g., Cloud Subscription)
# contract_duration_months : Contract length (e.g., 12, 24, 36)
# booking_date             : When recorded in system (e.g., 2023-03-15)
# deal_stage               : Deal status (e.g., Closed Won, Pending)
# sales_region             : Sales territory (e.g., North America, EMEA)

# ============================================================================
# RECOGNIZED REVENUE (Accounting System) - When revenue is recorded
# ============================================================================
# recognition_id           : Unique recognition ID (e.g., REC-000001)
# deal_id                  : Links to deal - MAY NOT MATCH! (e.g., DEAL-10001)
# customer_name            : Customer name - MAY VARY! (e.g., TechSystems)
# recognition_date         : Official recognition date (e.g., 2023-04-01)
# recognized_amount        : Amount recognized (e.g., $10,000.00)
# recognition_period       : Accounting period (e.g., 2023-04)
# revenue_type             : Revenue category (e.g., License Revenue)
# gl_account               : GL account number (e.g., 4000-1000)
# accounting_month         : Booking month (e.g., 2023-04)




import pandas as pd
import numpy as np
from datetime import datetime
import sqlalchemy
import requests

# ---------- CONFIGURATION ----------
DEFAULT_CONFIG = {
    "SLACK_WEBHOOK_URL": "https://hooks.slack.com/services/example123",
    "SLACK_CHANNEL": "#slackchannel",
    "SLACK_BOT_NAME": "bot_name",
    "THRESHOLD": 0.01 , # 1% mismatch allowed
    "DATABSE_CONFIG" : {
        "SERVER" : "your_server_name" ,
        "DB_ACCOUNTING" : "accounting_db",
        "DB_ANALYTICS":  "analytics_db",
        }
}

# Custom function to
def calculate_close_date(row):
    """calculate close_date for booked contracts ."""
    return row['booking_date'] + pd.DateOffset(months=row['contract_duration_months'])


# ----------------------------------

def get_current_month_period():
    """Get the start date of the current month."""
    today = datetime.now()
    start_of_month = today.replace(day=1)
    return start_of_month.date()


def load_data_from_db(conn_acc ,conn_ana , current_month):
    """
    Load and preprocess data from SQL Server  database.

    Args:
        current_month (date): Current month period for filtering
        conn_ana: connection string for analytics database
        conn_acc: connection string for accounting database

    Returns:
        tuple: (analytics_df, recurring_rev, oneOf_rev)

    """


    engine_acc = sqlalchemy.create_engine(conn_acc)
    engine_ana = sqlalchemy.create_engine(conn_ana)

    # Load data
    analytics_df = pd.read_sql("SELECT * FROM deals", engine_ana)
    accounting_df = pd.read_sql("SELECT * FROM revenue_recognition", engine_acc)

    # Preprocess analytics data
    analytics_df = analytics_df.copy()
    analytics_df["contract_date"] = pd.to_datetime(analytics_df["contract_date"])
    analytics_df["booking_date"] = pd.to_datetime(analytics_df["booking_date"])
    analytics_df["close_date"] = analytics_df.apply(calculate_close_date, axis=1)
    analytics_df["monthly_value"] = np.round(
        analytics_df["contract_value"] / analytics_df["contract_duration_months"], 2
    )
    analytics_df = analytics_df [ (pd.to_datetime(current_month) <= analytics_df["close_date"]) ]

    # Preprocess accounting data
    accounting_df = accounting_df.copy()
    accounting_df["recognition_date"] = pd.to_datetime(accounting_df["recognition_date"], format="ISO8601")
    accounting_df["recognition_period"] = pd.to_datetime(accounting_df["recognition_period"], format="ISO8601")

    # Filter for current month
    accounting_df = accounting_df[accounting_df["recognition_period"] == str(current_month)]

    # Categorize revenue
    accounting_df["is_recurring"] = accounting_df["revenue_type"].apply(
        lambda x: x in ["Subscription Revenue", "Support Revenue", "Maintenance Revenue", "Service Revenue"]
    )
    # Extract Recurring & One-off revenue
    recurring_rev = accounting_df[accounting_df["is_recurring"] == True]
    oneOf_rev = accounting_df[accounting_df["is_recurring"] == False]


    return analytics_df, recurring_rev, oneOf_rev


def reconcile_data(analytics_df, recurring_rev, threshold=0.01):
    """
    Reconcile analytics and recurring accounting data .

    Args:
        analytics_df (DataFrame): Analytics revenue data
        recurring_rev (DataFrame): Recurring revenue data from accounting
        threshold (float): Mismatch threshold percentage

    Returns:
        tuple: (merged_df, summary_stats, total_mismatch_records, mismatch_records_df)
    """
    # Merge datasets
    merged = pd.merge(analytics_df, recurring_rev, on="deal_id", how="outer")

    # Calculate differences
    merged["difference"] = merged["monthly_value"] - merged["recognized_amount"]

    # Select relevant columns
    merged = merged[[
        "deal_id", "contract_value", "monthly_value", "contract_duration_months",
        "booking_date", "deal_stage", "recognition_date", "recognition_period",
        "recognized_amount", "revenue_type", "accounting_month"
    ]]

    # Calculate mismatch rate
    merged['mismatch_rate_%'] = abs(merged['recognized_amount'] - merged['monthly_value']) / merged[
        'recognized_amount'] * 100

    # Flag records
    def flag(row):
        if pd.isna(row["recognized_amount"]):
            return "Missing in Accounting"
        elif pd.isna(row["monthly_value"]):
            return "Missing in Analytics"
        elif row["mismatch_rate_%"] > threshold:
            return "Mismatch amount"
        else:
            return "OK"

    merged["status"] = merged.apply(flag, axis=1)

    # Calculate summary statistics
    total_mismatch_records = len(merged[merged["status"] != "OK"])
    mismatch_records_df = merged[merged["status"] != "OK"]

    total_acc = merged['recognized_amount'].sum()
    total_ana = merged['monthly_value'].sum()
    overall_mismatch_rate = abs(total_acc - total_ana) / total_acc * 100 if total_acc > 0 else 0

    summary_stats = {
        "status_counts": merged["status"].value_counts().to_dict(),
        "total_booked": merged["monthly_value"].sum(skipna=True),
        "total_recognized": merged["recognized_amount"].sum(skipna=True),
        "total_diff": merged["monthly_value"].sum(skipna=True) - merged["recognized_amount"].sum(skipna=True),
        "overall_mismatch_rate": overall_mismatch_rate,
        "total_mismatch_records": total_mismatch_records
    }

    return merged, summary_stats, total_mismatch_records, mismatch_records_df


def generate_slack_message(summary_stats, date_str, threshold):
    """
    Generate Slack message blocks for the reconciliation report.

    Args:
        summary_stats (dict): Summary statistics from reconciliation
        date_str (str): Date string for the report
        threshold (float): Mismatch threshold

    Returns:
        dict: Slack message payload
    """
    # Determine alert emoji and color
    if summary_stats['overall_mismatch_rate'] > threshold:
        alert_emoji = "üö®"
        color = "#FF0000"  # Red
    else:
        alert_emoji = "‚úÖ"
        color = "#36A64F"  # Green

    # Format status counts
    status_text = "\n".join([f"‚Ä¢ {status}: {count}" for status, count in summary_stats['status_counts'].items()])

    slack_payload = {
        "channel": DEFAULT_CONFIG["SLACK_CHANNEL"],
        "username": DEFAULT_CONFIG["SLACK_BOT_NAME"],
        "attachments": [
            {
                "color": color,
                "blocks": [
                    {
                        "type": "header",
                        "text": {
                            "type": "plain_text",
                            "text": f"{alert_emoji} Monthly Revenue Reconciliation Report - {date_str}"
                        }
                    },
                    {
                        "type": "section",
                        "fields": [
                            {
                                "type": "mrkdwn",
                                "text": f"*Total Booked (Analytics):*\n${summary_stats['total_booked']:,.2f}"
                            },
                            {
                                "type": "mrkdwn",
                                "text": f"*Total Recognized (Accounting):*\n${summary_stats['total_recognized']:,.2f}"
                            },
                            {
                                "type": "mrkdwn",
                                "text": f"*Difference:*\n${summary_stats['total_diff']:,.2f}"
                            },
                            {
                                "type": "mrkdwn",
                                "text": f"*Mismatch Rate:*\n{summary_stats['overall_mismatch_rate']:.2f}%"
                            },
                            {
                                "type": "mrkdwn",
                                "text": f"*Mismatch Records:*\n{summary_stats['total_mismatch_records']}"
                            },
                            {
                                "type": "mrkdwn",
                                "text": f"*Threshold:*\n{threshold * 100}%"
                            }
                        ]
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*Status Summary:*\n{status_text}"
                        }
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"{'üö® ALERT: Mismatch exceeds threshold!' if summary_stats['overall_mismatch_rate'] > threshold else '‚úÖ All good. Within tolerance.'}"
                        }
                    },
                    {
                        "type": "context",
                        "elements": [
                            {
                                "type": "mrkdwn",
                                "text": "Generated by Automated Revenue Reconciliation System"
                            }
                        ]
                    }
                ]
            }
        ]
    }

    return slack_payload


def send_slack_message(slack_payload, webhook_url):
    """
    Send message to Slack via webhook.

    Args:
        slack_payload (dict): Slack message payload
        webhook_url (str): Slack webhook URL

    Returns:
        bool: True if message sent successfully
    """
    try:
        response = requests.post(
            webhook_url,
            json=slack_payload,
            headers={'Content-Type': 'application/json'}
        )

        if response.status_code == 200:
            print("‚úÖ Slack message sent successfully!")
            return True
        else:
            print(f"‚ùå Failed to send Slack message: {response.status_code} - {response.text}")
            return False

    except Exception as e:
        print(f"‚ùå Error sending Slack message: {e}")
        return False


def export_to_csv(merged_df, date_str, filename_prefix="reconciliation_report"):
    """
    Export reconciliation results to CSV.

    Args:
        merged_df (DataFrame): Merged reconciliation data
        date_str (str): Date string for filename
        filename_prefix (str): Prefix for the CSV filename
    """
    filename = f"{filename_prefix}_{date_str}.csv"
    merged_df.to_csv(filename, index=False)
    print(f"‚úÖ Report exported to {filename}")


def run_reconciliation_pipeline(config=None):
    """
    Main function to run the complete reconciliation pipeline.

    Args:
        config (dict): Configuration parameters. If None, uses DEFAULT_CONFIG and DATABASE_CONFIG

    Returns:
        tuple: (merged_df, summary_stats, email_sent)
    """
    if config is None:
        config = DEFAULT_CONFIG

    # Get current date
    current_month = get_current_month_period()
    date_str = datetime.now().strftime("%Y-%m-%d")

    try:
        # Load data
        print("üìä Loading data from database...")

        conn_acc = f"mssql+pyodbc://@{DEFAULT_CONFIG["DATABSE_CONFIG"]["SERVER"]}/{DEFAULT_CONFIG["DATABSE_CONFIG"]["DB_ACCOUNTING"]}?driver=ODBC+Driver+17+for+SQL+Server"
        conn_ana = f"mssql+pyodbc://@{DEFAULT_CONFIG["DATABSE_CONFIG"]["SERVER"]}/{DEFAULT_CONFIG["DATABSE_CONFIG"]["DB_ANALYTICS"]}?driver=ODBC+Driver+17+for+SQL+Server"

        analytics_df, recurring_rev, oneOf_rev = load_data_from_db(conn_acc , conn_ana, current_month)

        # Reconcile data
        print("üîç Reconciling data...")
        merged_df, summary_stats, total_mismatch_records, mismatch_records_df = reconcile_data(
            analytics_df, recurring_rev, config["THRESHOLD"]
        )

        # Generate and send Slack message
        print("üí¨ Generating Slack report...")
        slack_payload = generate_slack_message(summary_stats, date_str, config["THRESHOLD"])
        slack_sent = send_slack_message(slack_payload, config["SLACK_WEBHOOK_URL"])

        # Export to CSV
        print("üíæ Exporting to CSV...")
        export_to_csv(merged_df, date_str)

        print("‚úÖ Reconciliation pipeline completed successfully!")
        return merged_df, summary_stats, slack_sent

    except Exception as e:
        print(f"‚ùå Error in reconciliation pipeline: {e}")
        return None, None, False


# Run the pipeline
if __name__ == "__main__":

    merged_df, summary_stats, email_sent = run_reconciliation_pipeline()

